# ğŸ§  S.E.N.S.E â€” Accessibility Wearable

> **CTRL+HACK+DEL 2.0 Hackathon Project**
> A real-time AI-powered wearable that helps visually impaired users navigate the world using spatial audio, haptic feedback, and computer vision.

## Architecture

```
Webcam (C270) â”€â”€â”€â”€â”€â”€â–º Raspberry Pi 4 (Brain) â—„â”€â”€â”€â”€â”€â”€ Arduino (Reflexes)
                          â”œâ”€â”€ Thread A: MJPEG Stream â†’ /video_feed
                          â”œâ”€â”€ Thread B: Distance Trigger â†’ Gemini 2.0 Flash
                          â”œâ”€â”€ ElevenLabs TTS â†’ USB Audio Output (~75ms)
                          â”œâ”€â”€ PySerial (115200) â† HC-SR04 Sensor Data
                          â””â”€â”€ WebSocket â†’ React Dashboard (neon overlays)
```

## Quick Start

### 1. Clone & Branch
```bash
git clone https://github.com/demardefrozen10/CTRL-HACK-DEL.git
cd CTRL-HACK-DEL
git checkout main
```

### 2. Install Dependencies (On Raspberry Pi)
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
# Ensure pyserial and opencv-python are installed
```

### 3. Environment Variables
Create a `.env` file in the root directory:
```
GEMINI_API_KEY=your_gemini_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
SERIAL_PORT=/dev/ttyACM0  # Raspberry Pi USB Port for Arduino
CAMERA_INDEX=0            # Default for USB Webcam
INFERENCE_INTERVAL_MS=5000 # Cooldown to prevent API spam
```

### 4. Run the Brain
```bash
python3 brain.py
```

## Hardware
- **Raspberry Pi 4** â€” Central Processing Unit (The Brain)
- **Logitech C270 Webcam** â€” 720p vision system
- **Arduino Nano** â€” Dedicated low-latency sensor controller (The Spinal Cord)
- **HC-SR04** â€” Ultrasonic distance sensor for immediate obstacle detection
- **Active Buzzer** - Multi-modal feedback (Variable frequency pulses based on proximity)
- **USB Sound Card** - Dedicated high-quality audio output for ElevenLabs

## System Logic
1. **The Spinal Cord (Arduino):** Handles immediate safety. It measures distance and triggers the buzzer pulses. It operates independently of the Pi to ensure zero-latency feedback.
2. **The Brain (Raspberry Pi):** Listens to the Arduino via Serial. When an object is detected within 50cm, it triggers the Gemini Vision API to describe the scene via ElevenLabs.

## API Endpoints
| Endpoint | Method | Description |
|---|---|---|
| `/video_feed` | GET | MJPEG stream (Sighted Ally View) |
| `/dashboard` | GET | Neon-on-black accessibility dashboard |
| `/ws` | WS | Real-time detections broadcast |
| `/health` | GET | System health and sensor status |

## Team
**Big 3** â€” CTRL+HACK+DEL 2.0
